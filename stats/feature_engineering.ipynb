{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6004589c-c4ea-42d5-b1f6-a1fb517bc96d",
   "metadata": {
    "id": "6004589c-c4ea-42d5-b1f6-a1fb517bc96d"
   },
   "source": [
    "# __Feature Engineering__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6dae8-8222-4c33-a420-dbc66b671ea7",
   "metadata": {
    "id": "c0e6dae8-8222-4c33-a420-dbc66b671ea7"
   },
   "source": [
    "## __Agenda__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6ddfd-1245-47de-af27-e9ee04aa76b7",
   "metadata": {
    "id": "49c6ddfd-1245-47de-af27-e9ee04aa76b7"
   },
   "source": [
    "In this lesson, we will cover the following concepts with the help of examples:\n",
    "- Introduction to Feature Engineering\n",
    "- Feature Engineering Methods\n",
    "- Transforming Variables\n",
    "  * Log Transformation\n",
    "  * Square Root Transformation\n",
    "  * Box-Cox Transformation\n",
    "- Features Scaling\n",
    "- Label Encoding\n",
    "- One Hot Encoding\n",
    "- Hashing\n",
    "    * Hashlib Module\n",
    "- Grouping Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c504ca-dddb-45c1-8ac6-bc08c3040eb5",
   "metadata": {
    "id": "06c504ca-dddb-45c1-8ac6-bc08c3040eb5"
   },
   "source": [
    "## __1. Introduction to Feature Engineering__\n",
    "It refers to the process of selecting, modifying, or creating new features (variables) from the raw data to improve the performance of machine learning models.\n",
    "- It involves transforming the data into a more suitable format, making it easier for models to learn patterns and make accurate predictions.\n",
    "- It is a critical step in the data preprocessing pipeline and plays a key role in the success of machine learning projects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb329e1-8059-4dfb-ac65-24a512f83108",
   "metadata": {
    "id": "ffb329e1-8059-4dfb-ac65-24a512f83108"
   },
   "source": [
    "## __2. Feature Engineering Methods__\n",
    "\n",
    "They introduce the concept of creating new features through mathematical operations, transformations, or combining existing variables.\n",
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_10_Feature_Engineering/Feature_Engineering_Methods.png)\n",
    "\n",
    "__Note:__ The __Data Wrangling__ lesson extensively addresses various feature engineering methods, including outlier handling, imputation, and data cleaning. Any aspects not covered in that lesson but deemed essential for feature engineering are comprehensively discussed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edffd67e-bf28-439f-8079-4c6d4c3ff647",
   "metadata": {
    "id": "edffd67e-bf28-439f-8079-4c6d4c3ff647"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df= pd.read_csv(\"../data/HousePrices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f834d0-58f9-492c-8dd0-3207391e387c",
   "metadata": {
    "id": "d2f834d0-58f9-492c-8dd0-3207391e387c"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a4ed7-133f-49cf-86e1-d7219afdbbd7",
   "metadata": {
    "id": "a69a4ed7-133f-49cf-86e1-d7219afdbbd7"
   },
   "outputs": [],
   "source": [
    "# Create a new feature 'total_rooms' by adding bedrooms and bathrooms\n",
    "df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f77a79-5b60-42fb-9e75-edc69945b9ea",
   "metadata": {
    "id": "60f77a79-5b60-42fb-9e75-edc69945b9ea"
   },
   "source": [
    "## __3. Transforming Variables__\n",
    "Transforming variables is a crucial aspect of feature engineering that involves modifying the scale, distribution, or nature of variables to meet certain assumptions or to make them more suitable for analysis or modeling.\n",
    "- Here are a few common techniques for transforming variables:\n",
    "1. Log transformation\n",
    "2. Square root transformation\n",
    "3. Box-cox transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385cc69-a2a8-44ee-9a0f-ca7b89cf512d",
   "metadata": {
    "id": "5385cc69-a2a8-44ee-9a0f-ca7b89cf512d"
   },
   "source": [
    "### __3.1 Log Transformation__\n",
    "\n",
    "Log transformation is useful for handling skewed data or reducing the impact of outliers. It applies the natural logarithm to the variable values and makes highly skewed distributions less skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58418f94-2e06-4c65-8c8c-b43590b52c51",
   "metadata": {
    "id": "58418f94-2e06-4c65-8c8c-b43590b52c51"
   },
   "outputs": [],
   "source": [
    "# Logarithmic transformation of the 'price' column\n",
    "df['log_price'] = df['price'].apply(np.log)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52887650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot for the 'price' and 'log_price' columns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.boxplot(x='price', data=df, ax=ax[0])\n",
    "sns.boxplot(x='log_price', data=df, ax=ax[1])\n",
    "ax[0].set_title('Boxplot of the price column')\n",
    "ax[1].set_title('Boxplot of the log_price column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5f6b1-f95d-4e8f-9208-d47722069a2b",
   "metadata": {
    "id": "53c5f6b1-f95d-4e8f-9208-d47722069a2b"
   },
   "source": [
    "### __3.2 Square Root Transformation__\n",
    "Square root transformation, like log transformation, effectively stabilizes variance and addresses skewed distributions. Although it's gentler than log transformation, it achieves the same objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d238bd-fe47-4466-95ac-2fcc4fd1b0ea",
   "metadata": {
    "id": "a1d238bd-fe47-4466-95ac-2fcc4fd1b0ea"
   },
   "outputs": [],
   "source": [
    "# Square root transforming the 'price' variable\n",
    "df['SquareRoot_price'] = df['price'].apply(np.sqrt)\n",
    "# Displaying the DataFrame with the new feature\n",
    "print(\"DataFrame with square root transformed 'price':\")\n",
    "df[['price', 'SquareRoot_price']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "sns.histplot(df['price'], ax=ax[0])\n",
    "sns.histplot(df['log_price'], ax=ax[1])\n",
    "sns.histplot(df['SquareRoot_price'], ax=ax[2])\n",
    "ax[0].set_title('Histogram of the price column')\n",
    "ax[1].set_title('Histogram of the log_price column')\n",
    "ax[2].set_title('Histogram of the SquareRoot_price column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a74c0-bcb0-45e3-b16f-74a5255c6f3f",
   "metadata": {
    "id": "ba5a74c0-bcb0-45e3-b16f-74a5255c6f3f"
   },
   "source": [
    "### __3.3 Box-Cox Transformation__\n",
    "\n",
    "The box-cox transformation is a family of power transformations that includes log and square root transformations.\n",
    "- It can handle a broader range of data distributions.\n",
    "\n",
    "- Ensuring positive data is crucial for the Box-Cox transformation because it involves taking the logarithm, which is undefined for zero or negative values. Adding a constant helps avoid mathematical errors and ensures the transformation can be applied effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcae436-c68f-495a-af02-b62f3c19e678",
   "metadata": {
    "id": "7dcae436-c68f-495a-af02-b62f3c19e678"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "# Applying Box-Cox transformation to 'sales' variable\n",
    "df['BoxCox_sqft'], best_lambda = boxcox(df['sqft_living'])\n",
    "\n",
    "# Displaying the DataFrame with the Box-Cox transformed 'sales' variable\n",
    "print(\"DataFrame with box-cox transformed price:\")\n",
    "df[['sqft_living', 'BoxCox_sqft']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a5bf1-c3ab-4c1d-9ce6-578e47b4ef36",
   "metadata": {
    "id": "cc2a5bf1-c3ab-4c1d-9ce6-578e47b4ef36"
   },
   "outputs": [],
   "source": [
    "print(best_lambda)\n",
    "# Create histogram for the 'sqft_living' and 'BoxCox_sqft' columns\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.histplot(df['sqft_living'], ax=ax[0])\n",
    "sns.histplot(df['BoxCox_sqft'], ax=ax[1])\n",
    "ax[0].set_title('Histogram of the sqft_living column')\n",
    "ax[1].set_title('Histogram of the BoxCox_sqft column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d1e372-7022-4409-8992-6be1828315aa",
   "metadata": {
    "id": "19d1e372-7022-4409-8992-6be1828315aa"
   },
   "source": [
    "## __4. Feature Scaling__\n",
    "Feature scaling is a technique used in machine learning and data preprocessing to standardize or normalize the range of independent variables or features of a dataset.\n",
    "\n",
    "- Min-max scaling transforms data to a specific range, typically between 0 and 1, preserving the relative differences between values. This normalization technique is ideal for datasets with known bounds, ensuring that all values are rescaled proportionally to fit within the specified range.\n",
    "\n",
    "- Standard scaling is preferable for normally distributed data to maintain mean-centeredness and consistent standard deviations.\n",
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_10_Feature_Engineering/Label_Encoding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b1b5-89f8-4a51-8226-62e50fccc4ca",
   "metadata": {
    "id": "0498b1b5-89f8-4a51-8226-62e50fccc4ca"
   },
   "outputs": [],
   "source": [
    "# Normalization using sickit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scaling numeric features using min-max scaling\n",
    "scaler = MinMaxScaler()\n",
    "df[['sqft_living_scaled', 'sqft_lot_scaled']] = scaler.fit_transform(df[['sqft_living', 'sqft_lot']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba019c-f331-451a-98ea-ac964019c3c7",
   "metadata": {
    "id": "2dba019c-f331-451a-98ea-ac964019c3c7"
   },
   "outputs": [],
   "source": [
    "# Standardization using sickit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling numeric features using standard scaling\n",
    "standard_sc = StandardScaler()\n",
    "df[['sqft_living_standard', 'sqft_lot_standard']] = standard_sc.fit_transform(df[['sqft_living', 'sqft_lot']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fdece-9785-4328-b7ff-d2d7ab134d04",
   "metadata": {
    "id": "e73fdece-9785-4328-b7ff-d2d7ab134d04"
   },
   "source": [
    "## __5. Label Encoding__\n",
    "\n",
    "Label encoding is a technique used to convert categorical labels into a numeric format, making it suitable for machine learning algorithms that require numerical input.\n",
    "- In label encoding, each unique category is assigned an integer value.\n",
    "- This is particularly useful when dealing with ordinal categorical data, where the order of categories matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0740a-4f5e-4596-a0ee-e249ae996d27",
   "metadata": {
    "id": "ace0740a-4f5e-4596-a0ee-e249ae996d27"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'size': ['small', 'medium', 'large', 'medium', 'small']}\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "# Before label encoding\n",
    "print(\"Original DataFrame:\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f4bdf-8cd8-401c-b271-6b0ce5321306",
   "metadata": {
    "id": "470f4bdf-8cd8-401c-b271-6b0ce5321306"
   },
   "outputs": [],
   "source": [
    "# Apply label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df2['size_encoded'] = label_encoder.fit_transform(df2['size'])\n",
    "\n",
    "# After label encoding\n",
    "print(\"\\nDataFrame after label encoding:\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9782718",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder.transform(['small', 'medium', 'large'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one hot encoding for the 'size' column\n",
    "df2n = pd.get_dummies(df2['size'])\n",
    "df2 = df2.merge(df2n, left_index=True, right_index=True)\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f106b-6958-4902-829c-959762efdf21",
   "metadata": {
    "id": "536f106b-6958-4902-829c-959762efdf21"
   },
   "outputs": [],
   "source": [
    "# Demonstrating label encoding using csv file\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding for the 'city' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['city_encoded'] = label_encoder.fit_transform(df['city'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one hot encoding for the 'city' column\n",
    "df_one_hot = pd.get_dummies(df['city'])\n",
    "df = pd.concat([df, df_one_hot], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3daac9-e1a9-4709-950c-3af7cc34e78c",
   "metadata": {
    "id": "9a3daac9-e1a9-4709-950c-3af7cc34e78c"
   },
   "outputs": [],
   "source": [
    "# Other solution, without sickit-learn\n",
    "df['city_encoded_v2'] = df['city'].astype('category').cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c3b95-2901-4e54-a771-2976415d4e91",
   "metadata": {
    "id": "956c3b95-2901-4e54-a771-2976415d4e91"
   },
   "outputs": [],
   "source": [
    "# Other solution, without sickit-learn\n",
    "my_cities = df['city'].unique()\n",
    "my_cities_labels = {city: i for i, city in enumerate(my_cities)}\n",
    "df['city_encoded_v3'] = df['city'].map(my_cities_labels)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16314969-492f-448d-943b-c14b62573090",
   "metadata": {
    "id": "16314969-492f-448d-943b-c14b62573090"
   },
   "source": [
    "## __6. One-Hot Encoding__\n",
    "\n",
    "One-hot encoding is a technique to represent categorical variables as binary vectors.\n",
    "- It is particularly useful when dealing with nominal categorical data, where there is no inherent order among categories.\n",
    "- In one-hot encoding, each unique category is transformed into a binary column, and only one column in each set of binary columns is _hot_ (or 1) to indicate the presence of that category.\n",
    "\n",
    "- It increases dataset dimensionality, facilitating categorical data representation. However, it can lead to increased complexity and computational overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d868ac-01f9-466c-a4b5-7e773139f4e8",
   "metadata": {
    "id": "28d868ac-01f9-466c-a4b5-7e773139f4e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'color': ['red', 'blue', 'green', 'red', 'green']}\n",
    "df3 = pd.DataFrame(data)\n",
    "\n",
    "# Before one-hot encoding\n",
    "print(\"Original DataFrame:\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dea910-5632-4164-a786-a053e41da078",
   "metadata": {
    "id": "93dea910-5632-4164-a786-a053e41da078"
   },
   "outputs": [],
   "source": [
    "# Apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df3['color'])\n",
    "df3 = pd.concat([df3, df_encoded], axis=1) # Can drop_first=True to avoid multicollinearity\n",
    "# After one-hot encoding\n",
    "print(\"\\nDataFrame after one-hot encoding:\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REad housing data\n",
    "df = pd.read_csv(\"../data/HousePrices.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b65d6-eeef-459a-ad4f-29c27f365fe7",
   "metadata": {
    "id": "447b65d6-eeef-459a-ad4f-29c27f365fe7"
   },
   "outputs": [],
   "source": [
    "# Demonstrating one-hot encoding using csv file\n",
    "# One-Hot Encoding for the 'view' column\n",
    "df_encode = pd.get_dummies(df['view'], drop_first=True)\n",
    "df = pd.concat([df, df_encode], axis=1)\n",
    "# After one-hot encoding\n",
    "print(\"\\nDataFrame after one-hot encoding:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523b7f8-3d9f-47e6-92a3-2ac68b67823e",
   "metadata": {
    "id": "6523b7f8-3d9f-47e6-92a3-2ac68b67823e"
   },
   "outputs": [],
   "source": [
    "# Same, using sickit-learn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "tr = enc.fit_transform(df[['view']])\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7843f4d-b8ae-4255-8081-ff17a96dff60",
   "metadata": {
    "id": "c7843f4d-b8ae-4255-8081-ff17a96dff60"
   },
   "outputs": [],
   "source": [
    "print(enc.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1479b-b9d3-4be5-8540-b0ee3c41e4b6",
   "metadata": {
    "id": "4ed1479b-b9d3-4be5-8540-b0ee3c41e4b6"
   },
   "outputs": [],
   "source": [
    "print(enc.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceaa580-b604-4848-bbba-2584afebe879",
   "metadata": {
    "id": "dceaa580-b604-4848-bbba-2584afebe879"
   },
   "outputs": [],
   "source": [
    "tr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3e6a1-df2b-4554-b5c4-11b182f8f65c",
   "metadata": {
    "id": "52f3e6a1-df2b-4554-b5c4-11b182f8f65c"
   },
   "outputs": [],
   "source": [
    "df_encode2= df.copy()\n",
    "# Convert the encoded array back to a DataFrame and change the column names to the original categories\n",
    "df_encode2[enc.categories_[0]] = tr.toarray()\n",
    "df_encode2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278e503-7239-4b0b-9f86-cf39e57d5eff",
   "metadata": {
    "id": "3278e503-7239-4b0b-9f86-cf39e57d5eff"
   },
   "outputs": [],
   "source": [
    "df_encode2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one hot encoding for the 'city' column\n",
    "one_hot_city_encoder = OneHotEncoder()\n",
    "tr_city = one_hot_city_encoder.fit_transform(df[['city']])\n",
    "df_encode3 = df.copy()\n",
    "df_encode3[one_hot_city_encoder.categories_[0]] = tr_city.toarray()\n",
    "print(df_encode3.head())\n",
    "print(df_encode3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e8803-6738-4bd4-8d4d-17fe0c293496",
   "metadata": {
    "id": "bd7e8803-6738-4bd4-8d4d-17fe0c293496"
   },
   "source": [
    "## __7. Hashing__\n",
    "\n",
    "It is a technique to convert input data (of variable length) into a fixed-length string of characters, typically a hash code.\n",
    "- The hash function takes an input (or message) and returns a fixed-size string of characters, which is typically a hexadecimal number.\n",
    "- It is commonly used for indexing data structures, checking data integrity, and hashing passwords.\n",
    "\n",
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Updated_Images/Lesson_10/10_01/Lesson_10_Feature_EngineeringHashing.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd85344-7c27-4c3f-9bfd-3d26f799d12d",
   "metadata": {
    "id": "dbd85344-7c27-4c3f-9bfd-3d26f799d12d"
   },
   "outputs": [],
   "source": [
    "# Example of hashing in Python\n",
    "data = \"Hello, Hashing!\"\n",
    "\n",
    "# Using the hash() function\n",
    "hash_value = hash(data)\n",
    "\n",
    "print(f\"Original data: {data}\")\n",
    "print(f\"Hash value: {hash_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068e16b-7c03-45eb-898f-f9669635169c",
   "metadata": {
    "id": "a068e16b-7c03-45eb-898f-f9669635169c"
   },
   "outputs": [],
   "source": [
    "# Demonstrating hashing using csv file\n",
    "# Hashing for the 'street' column\n",
    "df['street_hashed'] = df['street'].apply(hash)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tc1z5BeibHx4",
   "metadata": {
    "id": "tc1z5BeibHx4"
   },
   "source": [
    "### __7.1 Hashlib Module__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BJ0y1r5gbChG",
   "metadata": {
    "id": "BJ0y1r5gbChG"
   },
   "source": [
    "The hashlib module in Python is used for generating hash values. It offers interfaces to different cryptographic hash algorithms like MD5, SHA-1, SHA-256, SHA-384, and SHA-512.\n",
    "\n",
    "- It enables the efficient use of hash functions, ensuring secure computations.\n",
    "- It provides reliability for hash-related operations.\n",
    "- It is widey used for cryptographic operations, data integrity, and password hashing.\n",
    "- It ensures convenience and robustness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X5SV3EiCbKYf",
   "metadata": {
    "id": "X5SV3EiCbKYf"
   },
   "source": [
    "Cryptographic hash algorithms vary in hash size and security levels.\n",
    "\n",
    "- For tasks where security is not a critical concern, you can opt for MD5 or SHA-1. However, it's important to note that both algorithms are deprecated due to vulnerabilities.\n",
    "\n",
    "- For security-sensitive applications, it's advisable to prioritize SHA-256, SHA-384, or SHA-512 due to their stronger security and larger hash sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kwwYbMe7bfZe",
   "metadata": {
    "id": "kwwYbMe7bfZe"
   },
   "outputs": [],
   "source": [
    "# Example of hashlib module in Python\n",
    "import hashlib\n",
    "\n",
    "# Input data\n",
    "data = b'Hello, world!'\n",
    "print(f\"Original data: {data.decode()} \\n\")\n",
    "\n",
    "# Calculate MD5 hash\n",
    "md5_hash = hashlib.md5(data).hexdigest()\n",
    "print(\"MD5 Hash:\", md5_hash)\n",
    "\n",
    "# Calculate SHA-1 hash\n",
    "sha1_hash = hashlib.sha1(data).hexdigest()\n",
    "print(\"SHA-1 Hash:\", sha1_hash)\n",
    "\n",
    "# Calculate SHA-256 hash\n",
    "sha256_hash = hashlib.sha256(data).hexdigest()\n",
    "print(\"SHA-256 Hash:\", sha256_hash)\n",
    "\n",
    "# Calculate SHA-384 hash\n",
    "sha384_hash = hashlib.sha384(data).hexdigest()\n",
    "print(\"SHA-384 Hash:\", sha384_hash)\n",
    "\n",
    "# Calculate SHA-512 hash\n",
    "sha512_hash = hashlib.sha512(data).hexdigest()\n",
    "print(\"SHA-512 Hash:\", sha512_hash)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blZPcj11bf7Y",
   "metadata": {
    "id": "blZPcj11bf7Y"
   },
   "source": [
    "In this example, the `hashlib` module is imported and input data is provided in bytes format. Hash values are then computed using the md5(), sha1(), sha256(), sha384(), and sha512() functions, and their hexadecimal representations are obtained using hexdigest()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FvFWQijcbjn_",
   "metadata": {
    "id": "FvFWQijcbjn_"
   },
   "outputs": [],
   "source": [
    "# Demonstrating MD5 hash function using csv file for the 'street' column\n",
    "\n",
    "street_column = df['street']\n",
    "hashed_streets = street_column.apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "\n",
    "# Replace the original street values with hash values\n",
    "df['hashed_street'] = hashed_streets\n",
    "\n",
    "# Optionally, write the updated DataFrame back to a CSV file\n",
    "df.to_csv('hashed_file.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ce2cf-fdc1-4f75-9031-3dd3b37e974a",
   "metadata": {
    "id": "329ce2cf-fdc1-4f75-9031-3dd3b37e974a"
   },
   "source": [
    "## __8. Grouping Operations__\n",
    "\n",
    "Grouping operations involve splitting a dataset into groups based on some criteria, applying a function to each group independently, and then combining the results.\n",
    "- This is a crucial step in data analysis and manipulation, allowing for insights into the data at a more granular level.\n",
    "- Grouping operations are commonly combined with aggregate functions to summarize data within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ca380-12a3-4756-91f2-743357d18a99",
   "metadata": {
    "id": "af0ca380-12a3-4756-91f2-743357d18a99"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'Category': ['Electronics', 'Clothing', 'Electronics', 'Clothing', 'Electronics'],\n",
    "        'Revenue': [500, 300, 700, 400, 600]}\n",
    "\n",
    "df4 = pd.DataFrame(data)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e299ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df4.groupby('Category')\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba5ce11-268f-472c-a600-15d2da41e11f",
   "metadata": {
    "id": "1ba5ce11-268f-472c-a600-15d2da41e11f"
   },
   "outputs": [],
   "source": [
    "# Grouping by 'Category' and calculating total revenue for each category\n",
    "revenues = grouped_df['Revenue'].sum()\n",
    "\n",
    "print(\"\\nGrouped DataFrame with total revenue:\")\n",
    "print(type(revenues))\n",
    "print(revenues.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8eb54-aff5-4322-ba3f-761ffb5956cb",
   "metadata": {
    "id": "dbf8eb54-aff5-4322-ba3f-761ffb5956cb"
   },
   "outputs": [],
   "source": [
    "# Grouping by 'city' and calculating the average price\n",
    "df_grouped_city = df.groupby('city')\n",
    "df_grouped_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kOssggebcDot",
   "metadata": {
    "id": "kOssggebcDot"
   },
   "outputs": [],
   "source": [
    "# Grouping by 'city' and calculating the average price\n",
    "average_price = df_grouped_city['price'].mean()\n",
    "average_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "StEMQHrecFm4",
   "metadata": {
    "id": "StEMQHrecFm4"
   },
   "outputs": [],
   "source": [
    "# Grouping by 'city' and calculating the minimum price\n",
    "df_grouped_min = df_grouped_city['price'].min()\n",
    "df_grouped_min.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94afb2-3dba-45e9-b345-4d271ec48a36",
   "metadata": {
    "id": "4b94afb2-3dba-45e9-b345-4d271ec48a36"
   },
   "source": [
    "## __9. Removing highly correlated features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e80348-fb4b-4b91-b7c8-1e44523b6aa8",
   "metadata": {
    "id": "11e80348-fb4b-4b91-b7c8-1e44523b6aa8"
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../data/HousePrices.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d8548-a5a0-4b86-a631-3d97808457bd",
   "metadata": {
    "id": "0d9d8548-a5a0-4b86-a631-3d97808457bd"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe wit hall columns except \"price\" (because we don't want to remove it)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_features = df.copy()\n",
    "df_features = df_features.drop(columns=['price'])\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb88f025-4ecb-49e7-8250-3f480d957665",
   "metadata": {
    "id": "eb88f025-4ecb-49e7-8250-3f480d957665",
    "outputId": "01312712-d436-4e02-c8da-e359d698417d"
   },
   "outputs": [],
   "source": [
    "# Compute correlation\n",
    "print(df_features.columns)\n",
    "features_to_corr = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "                    'floors', 'sqft_above',\n",
    "                    'sqft_basement', 'yr_built', 'yr_renovated']\n",
    "df_corr = df_features[features_to_corr].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856bdaa7-709f-4ec9-9484-94dd7d606130",
   "metadata": {
    "id": "856bdaa7-709f-4ec9-9484-94dd7d606130"
   },
   "outputs": [],
   "source": [
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f5e1d-e4ea-48b5-bb72-04df7832a171",
   "metadata": {
    "id": "920f5e1d-e4ea-48b5-bb72-04df7832a171"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(df_corr,annot=True,cmap='coolwarm')\n",
    "plt.title(\"Heat map of the correlation matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed246d92-4f8d-4571-b570-82ba13155c3e",
   "metadata": {
    "id": "ed246d92-4f8d-4571-b570-82ba13155c3e"
   },
   "outputs": [],
   "source": [
    "df_corr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bb562-8c29-4090-bc73-e0f982a51095",
   "metadata": {
    "id": "b76bb562-8c29-4090-bc73-e0f982a51095"
   },
   "outputs": [],
   "source": [
    "df_corr.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08f075-564b-40e6-ba56-020cc10e78b5",
   "metadata": {
    "id": "5d08f075-564b-40e6-ba56-020cc10e78b5"
   },
   "outputs": [],
   "source": [
    "(df_corr.iloc[2,3:]>0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090f9c4-a239-478f-801a-7a9ddae28898",
   "metadata": {
    "id": "4090f9c4-a239-478f-801a-7a9ddae28898"
   },
   "outputs": [],
   "source": [
    "cols = df_corr.columns\n",
    "cols_after_corr = list(cols)\n",
    "\n",
    "for i in range(df_corr.shape[0]):\n",
    "    if ((df_corr.iloc[i,i+1:].abs()>0.5).sum()>0.1):\n",
    "        cols_after_corr.remove(cols[i])\n",
    "        print(\"Removing\",cols[i])\n",
    "\n",
    "print(len(cols_after_corr))\n",
    "cols_after_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37259b11-e541-4604-87bc-6c098130c2ed",
   "metadata": {
    "id": "37259b11-e541-4604-87bc-6c098130c2ed"
   },
   "outputs": [],
   "source": [
    "df_features_after_corr = df_features[cols_after_corr]\n",
    "df_features_after_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e589ceb-ffbd-45fb-ab44-c622684e31ec",
   "metadata": {
    "id": "1e589ceb-ffbd-45fb-ab44-c622684e31ec"
   },
   "outputs": [],
   "source": [
    "df_features_after_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "47f47f93-336f-4eae-919f-aa652180e118",
   "metadata": {
    "id": "47f47f93-336f-4eae-919f-aa652180e118"
   },
   "outputs": [],
   "source": [
    "df_corr = df_features_after_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37120c61-e878-4325-95cd-31ec01dda0ab",
   "metadata": {
    "id": "37120c61-e878-4325-95cd-31ec01dda0ab"
   },
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(df_corr,annot=True,cmap='coolwarm')\n",
    "plt.title(\"Heat map of the correlation matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159bb60-8e57-4d82-b8d8-16a7f30d7180",
   "metadata": {
    "id": "e159bb60-8e57-4d82-b8d8-16a7f30d7180"
   },
   "source": [
    "# __Assisted Practice__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49f2ff-f63d-43a5-ac32-f76893c7f143",
   "metadata": {
    "id": "5b49f2ff-f63d-43a5-ac32-f76893c7f143"
   },
   "source": [
    "## __Problem Statement:__\n",
    "A botanical research team is conducting a comprehensive analysis of iris flowers, aiming to derive valuable insights from their characteristics. The team wants to explore feature engineering techniques to understand and visualize the relationships within the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61c7ac-2613-4d4d-b979-d6a31a0e92f2",
   "metadata": {
    "id": "0f61c7ac-2613-4d4d-b979-d6a31a0e92f2"
   },
   "source": [
    "## __Steps to Perform:__\n",
    "- Understand the Dataset: Get familiar with the Iris dataset and its features\n",
    "- Engineer Features: Create new features like sepal area and petal area\n",
    "- Transform Variables: If the features are not normally distributed, apply transformations\n",
    "- Scale Features: Use Min-Max Scaling or standard scaling to scale the features\n",
    "- Encode Labels: Convert the categorical data (species) into numerical data using label encoding\n",
    "- One Hot Encoding: Apply one hot encoding on the species feature and compare with label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21cc31-ba78-422b-8fa3-8b58cdabebcf",
   "metadata": {
    "id": "2b21cc31-ba78-422b-8fa3-8b58cdabebcf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
